{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_colwidth', 2000)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import implicit\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "megarelation = pd.read_csv('../data/raw/кружки/MegaRelation_hackaton.csv', sep=';')\n",
    "classificator = pd.read_csv('../data/raw/кружки/Classificator_hachaton.csv', sep=';')\n",
    "org = pd.read_csv('../data/raw/кружки/org_hackaton.csv', sep=';')\n",
    "services = pd.read_csv('../data/raw/кружки/services_hackaton.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for idx, row in classificator.iterrows():\n",
    "    id_ = row['id_классификатора']\n",
    "    if pd.isna(id_):\n",
    "        l.append('')\n",
    "    else:\n",
    "        x = classificator[classificator['id_классификатора'] == int(id_)]['Наименование'].tolist()[0]\n",
    "        l.append(x)\n",
    "        \n",
    "classificator['наименование_классификатора'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for idx, row in classificator.iterrows():\n",
    "    parent_id = row['id_родительского_классификатора']\n",
    "    if pd.isna(parent_id):\n",
    "        l.append('')\n",
    "    else:\n",
    "        x = classificator[classificator['id_классификатора'] == int(parent_id)]['Наименование'].tolist()[0]\n",
    "        l.append(x)\n",
    "        \n",
    "classificator['наименование_родительского_классификатора'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "megarelation = megarelation[[\n",
    "    'id_зачисления',\n",
    "    'id_ученика',\n",
    "    'id_организации',\n",
    "    'id_заявления',\n",
    "    'id_услуги',\n",
    "]]\n",
    "\n",
    "# classificator = classificator[[\n",
    "#     'id_ученика',\n",
    "#     'id_организации',\n",
    "#     'id_услуги',\n",
    "# ]]\n",
    "\n",
    "services = services[[\n",
    "    'id_услуги',\n",
    "    'Классификатор_услуги',\n",
    "    'id_организации',\n",
    "    'Наименование_услуги',\n",
    "]]\n",
    "\n",
    "megarelation = megarelation.drop_duplicates()\n",
    "#classificator = classificator.drop_duplicates()\n",
    "org = org.drop_duplicates()\n",
    "services = services.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 5)\n",
      "(302, 5)\n"
     ]
    }
   ],
   "source": [
    "# Оставлю только один, а то по два метро на один орг указано часто:\n",
    "print(org.shape)\n",
    "org = org[org.index.isin(org.drop('Метро', axis=1).drop_duplicates().index)]\n",
    "print(org.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(megarelation, services, on='id_услуги')\n",
    "df['id_организации'] = df['id_организации_x']\n",
    "df = df.drop(columns=['id_организации_x', 'id_организации_y'])\n",
    "df = pd.merge(df, org, on='id_организации')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_зачисления</th>\n",
       "      <th>id_ученика</th>\n",
       "      <th>id_заявления</th>\n",
       "      <th>id_услуги</th>\n",
       "      <th>Классификатор_услуги</th>\n",
       "      <th>Наименование_услуги</th>\n",
       "      <th>id_организации</th>\n",
       "      <th>полное_наименование</th>\n",
       "      <th>краткое_наименование</th>\n",
       "      <th>улица</th>\n",
       "      <th>Метро</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1325954</td>\n",
       "      <td>25969.0</td>\n",
       "      <td>950832.0</td>\n",
       "      <td>39178</td>\n",
       "      <td>3000001</td>\n",
       "      <td>Архитектура</td>\n",
       "      <td>30</td>\n",
       "      <td>Государственное бюджетное учреждение дополнительного образования города Москвы \"Детская школа искусств \"СТАРТ\" архитектурно-художественного профиля\"</td>\n",
       "      <td>ГБУДО г. Москвы \"ДШИ \"СТАРТ\"</td>\n",
       "      <td>Зоологическая улица</td>\n",
       "      <td>Баррикадная</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2879918</td>\n",
       "      <td>158129.0</td>\n",
       "      <td>989658.0</td>\n",
       "      <td>39178</td>\n",
       "      <td>3000001</td>\n",
       "      <td>Архитектура</td>\n",
       "      <td>30</td>\n",
       "      <td>Государственное бюджетное учреждение дополнительного образования города Москвы \"Детская школа искусств \"СТАРТ\" архитектурно-художественного профиля\"</td>\n",
       "      <td>ГБУДО г. Москвы \"ДШИ \"СТАРТ\"</td>\n",
       "      <td>Зоологическая улица</td>\n",
       "      <td>Баррикадная</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_зачисления  id_ученика  id_заявления  id_услуги  Классификатор_услуги  \\\n",
       "0        1325954     25969.0      950832.0      39178               3000001   \n",
       "1        2879918    158129.0      989658.0      39178               3000001   \n",
       "\n",
       "  Наименование_услуги  id_организации  \\\n",
       "0         Архитектура              30   \n",
       "1         Архитектура              30   \n",
       "\n",
       "                                                                                                                                    полное_наименование  \\\n",
       "0  Государственное бюджетное учреждение дополнительного образования города Москвы \"Детская школа искусств \"СТАРТ\" архитектурно-художественного профиля\"   \n",
       "1  Государственное бюджетное учреждение дополнительного образования города Москвы \"Детская школа искусств \"СТАРТ\" архитектурно-художественного профиля\"   \n",
       "\n",
       "           краткое_наименование                улица        Метро  \n",
       "0  ГБУДО г. Москвы \"ДШИ \"СТАРТ\"  Зоологическая улица  Баррикадная  \n",
       "1  ГБУДО г. Москвы \"ДШИ \"СТАРТ\"  Зоологическая улица  Баррикадная  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator['Классификатор_услуги'] = classificator['id_классификатора']\n",
    "classificator = classificator.drop(columns=['id_классификатора'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, classificator, on='Классификатор_услуги')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помёрджил!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(645286, 15)\n",
      "(514163, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.dropna(subset=['id_ученика', 'id_услуги', 'Метро', 'id_заявления'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id_ученика'] = df['id_ученика'].astype(int)\n",
    "df['id_заявления'] = df['id_заявления'].astype(int)\n",
    "df['id_услуги'] = df['id_услуги'].astype(int)\n",
    "\n",
    "df['id_родительского_классификатора'] = df['id_родительского_классификатора'].fillna(0)\n",
    "df['id_родительского_классификатора'] = df['id_родительского_классификатора'].astype(int)\n",
    "\n",
    "df['id_родительского_классификатора'] = df['id_родительского_классификатора'].fillna(0)\n",
    "df['id_родительского_классификатора'] = df['id_родительского_классификатора'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Наименование'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({\n",
    "    'id_зачисления': 'zachislenie_id',\n",
    "    'id_ученика': 'user_id',\n",
    "    'id_заявления': 'zayavlenie_id',\n",
    "    'id_услуги': 'service_id',\n",
    "    'Классификатор_услуги': 'service_classificator_id',\n",
    "    'Наименование_услуги': 'service_name',\n",
    "    'id_организации': 'org_id',\n",
    "    'полное_наименование': 'org_name_long',\n",
    "    'краткое_наименование': 'org_name_short',\n",
    "    'улица': 'org_street',\n",
    "    'Метро': 'org_metro',\n",
    "    'id_родительского_классификатора': 'service_classificator_parent_id',\n",
    "    'наименование_классификатора': 'service_classificator_name',\n",
    "    'наименование_родительского_классификатора': 'service_classificator_parent_name',\n",
    "}, axis = 'columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    'zachislenie_id',\n",
    "    'zayavlenie_id',\n",
    "    'user_id',\n",
    "    'service_id',\n",
    "    'service_name',\n",
    "    'service_classificator_id',\n",
    "    'service_classificator_name',\n",
    "    'service_classificator_parent_id',\n",
    "    'service_classificator_parent_name',\n",
    "    'org_id',\n",
    "    'org_name_short',\n",
    "    'org_name_long',\n",
    "    'org_street',\n",
    "    'org_metro',\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## метро"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://data.mos.ru/classifier/7704786030-stantsii-moskovskogo-metropolitena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro = pd.read_csv('../data/interim/data-6467-2020-10-26.csv', encoding='cp1251', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждой станции получу ближайшие к ней, то есть из её же района:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['район Лефортово', 'район Лефортово', 'район Лефортово']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metro[metro['Station'] == 'Авиамоторная']['District'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro2nearest = {k: [] for k in sorted(metro['Station'].unique())}\n",
    "\n",
    "#for st in metro[metro['District'] == metro[metro['Line'] == k]['District'][0]]['Line'].unique()\n",
    "\n",
    "for k in metro2nearest:\n",
    "    district = metro[metro['Station'] == k]['District'].tolist()[0]\n",
    "    stations = sorted([x for x in metro[metro['District'] == district]['Station'].unique().tolist()])\n",
    "    metro2nearest[k] = stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nearest_metro'] = df['org_metro'].map(metro2nearest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['service_classificator_parent_name'] + '__'  + df['service_classificator_name'] + '__' + df['service_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('../data/interim/sections.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesianPersonalizedRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import implicit\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SECTIONS_DF = '../data/processed/sections.parquet'\n",
    "PATH_TO_SECTIONS_MODEL = '../data/processed/sections_model.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df):\n",
    "    data = df.copy()\n",
    "    data = data.dropna(subset=['user_id', 'service_id'])\n",
    "    data = data.drop_duplicates(subset=['user_id', 'service_id'])\n",
    "    data = data[['user_id', 'service_id']]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PATH_TO_SECTIONS_DF)\n",
    "data = prepare_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_item = CategoricalDtype(sorted(data['service_id'].unique()), ordered=True)\n",
    "c_user = CategoricalDtype(sorted(data['user_id'].unique()), ordered=True)\n",
    "\n",
    "data['service_id'] = data['service_id'].astype(c_item)\n",
    "data['user_id'] = data['user_id'].astype(c_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3826bb72175e4102a18b1cc070ae2464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# to categorical\n",
    "data['user_id'] = data['user_id'].astype(c_user)\n",
    "data['service_id'] = data['service_id'].astype(c_item)\n",
    "\n",
    "train_data = csr_matrix(\n",
    "    (np.ones(len(data)), (data['user_id'].cat.codes, data['service_id'].cat.codes)),\n",
    "    shape=(len(c_user.categories), len(c_item.categories))\n",
    ")\n",
    "\n",
    "CONFIDENCE = 2\n",
    "model = implicit.bpr.BayesianPersonalizedRanking(\n",
    "    factors=200,\n",
    "    iterations=500,\n",
    "    random_state=567,\n",
    "    verify_negative_samples=True,\n",
    ")\n",
    "\n",
    "model.fit(CONFIDENCE * train_data.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TO_SECTIONS_MODEL, 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TO_SECTIONS_MODEL, 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = None\n",
    "name = data['user_id'].sample(n=1, random_state=random_state).tolist()[0]\n",
    "user_id = list(c_user.categories).index(name)\n",
    "\n",
    "recommended_items = model.recommend(user_id, train_data, N=10,\n",
    "                                    filter_already_liked_items=True,\n",
    "                                    #recalculate_user=True\n",
    "                                   )\n",
    "recommended_items = [list(c_item.categories)[x[0]] for x in recommended_items]\n",
    "already = data[data['user_id'] == name]['service_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALREADY\n",
      "['Студия художественного творчества', 'Студия художественного творчества', 'Студия художественного творчества.', 'Студия художественного творчества.', 'Кружок  \"Английский язык для школьников\"', 'Английский язык для школьников.']\n",
      "\n",
      "RECOMMENDED\n",
      "['Студия танцевального фитнеса \"Зумба\"', 'Студия Оригами', 'Студия художественного творчества.', ' Студия современного танца \"Мастер Данс\"', 'Оригами', 'Секция шахмат.', 'Таэквон-до секция', 'Песочная анимация.', 'Секция \"Шахматы\".', 'Колибри.']\n"
     ]
    }
   ],
   "source": [
    "# print('ALREADY')\n",
    "# print(already), \n",
    "\n",
    "# print()\n",
    "\n",
    "# print('RECOMMENDED')\n",
    "# print(recommended_items)\n",
    "\n",
    "print('ALREADY')\n",
    "print([df[df['service_id'] == x]['service_name'].unique().tolist()[0] for x in already])\n",
    "\n",
    "print()\n",
    "\n",
    "print('RECOMMENDED')\n",
    "print([df[df['service_id'] == x]['service_name'].unique().tolist()[0] for x in recommended_items])\n",
    "\n",
    "# на вход список айдишник  того что у юзера было\n",
    "# на выходе список рекомендаций (название, описание, урл картинки)\n",
    "# для каждого большого класса можно картинку крутую придумать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "mystem = Mystem()\n",
    "\n",
    "def clean_text(text):\n",
    "    try:\n",
    "        tokens = mystem.lemmatize(text.lower())\n",
    "    except BrokenPipeError:\n",
    "        mystem.close\n",
    "        mystem.start\n",
    "        tokens = mystem.lemmatize(text.lower())\n",
    "    \n",
    "    return [x for x in tokens if x not in ['\\n', ' ']]\n",
    "\n",
    "\n",
    "def remove_dublicates_by_tokens(already, recomendations):\n",
    "    cleaned_already = [clean_text(x) for x in already]\n",
    "    cleaned_recomendations = [clean_text(x) for x in recomendations]\n",
    "    idxs = [idx for idx, x in enumerate(cleaned_recomendations) if x not in cleaned_already]\n",
    "    return [recomendations[idx] for idx in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended = [df[df['service_id'] == x]['service_name'].unique().tolist()[0] for x in recommended_items]\n",
    "already = [df[df['service_id'] == x]['service_name'].unique().tolist()[0] for x in already]\n",
    "recommended = remove_dublicates_by_tokens(already, recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаю чтобы по айдишнику отдавала текст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Код для предикта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "\n",
    "PATH_TO_SECTIONS_DF = 'sections.parquet'\n",
    "PATH_TO_SECTIONS_MODEL = 'sections_model.pickle'\n",
    "\n",
    "mystem = Mystem()\n",
    "\n",
    "def prepare_df(df):\n",
    "    data = df.copy()\n",
    "    data = data.dropna(subset=['user_id', 'service_id'])\n",
    "    data = data.drop_duplicates(subset=['user_id', 'service_id'])\n",
    "    data = data[['user_id', 'service_id']]\n",
    "    return data\n",
    "\n",
    "df = pd.read_parquet(PATH_TO_SECTIONS_DF)\n",
    "data = prepare_df(df)\n",
    "\n",
    "c_item = CategoricalDtype(sorted(data['service_id'].unique()), ordered=True)\n",
    "c_user = CategoricalDtype(sorted(data['user_id'].unique()), ordered=True)\n",
    "\n",
    "data['service_id'] = data['service_id'].astype(c_item)\n",
    "data['user_id'] = data['user_id'].astype(c_user)\n",
    "\n",
    "# to categorical\n",
    "data['user_id'] = data['user_id'].astype(c_user)\n",
    "data['service_id'] = data['service_id'].astype(c_item)\n",
    "\n",
    "train_data = csr_matrix(\n",
    "    (np.ones(len(data)), (data['user_id'].cat.codes, data['service_id'].cat.codes)),\n",
    "    shape=(len(c_user.categories), len(c_item.categories))\n",
    ")\n",
    "\n",
    "with open(PATH_TO_SECTIONS_MODEL, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "\n",
    "def recommend_by_userid(name, df, data, c_item, c_user, model):\n",
    "    \"\"\"\n",
    "    name это айди юзера для которого хотим рекомендовать\n",
    "    например 10 или 93126\n",
    "    \"\"\"\n",
    "    user_id = list(c_user.categories).index(name)\n",
    "\n",
    "    recommended_items = model.recommend(\n",
    "        user_id,\n",
    "        train_data,\n",
    "        N=10,\n",
    "        filter_already_liked_items=True,\n",
    "    )\n",
    "\n",
    "    recommended_items = [list(c_item.categories)[x[0]] for x in recommended_items]\n",
    "    already = data[data['user_id'] == name]['service_id'].unique().tolist()\n",
    "\n",
    "    recommended = [df[df['service_id'] == x]['service_name'].unique().tolist()[0] for x in recommended_items]\n",
    "    already = [df[df['service_id'] == x]['service_name'].unique().tolist()[0] for x in already]\n",
    "    recomendations = remove_dublicates_by_tokens(already, recommended)\n",
    "\n",
    "    return already, recomendations\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    try:\n",
    "        if text:\n",
    "            tokens = mystem.lemmatize(text.lower())\n",
    "        else:\n",
    "            return text\n",
    "    except BrokenPipeError:\n",
    "        mystem.close()\n",
    "        mystem.start()\n",
    "        tokens = mystem.lemmatize(text.lower())\n",
    "\n",
    "    return [x for x in tokens if x not in ['\\n', ' ']]\n",
    "\n",
    "\n",
    "def remove_dublicates_by_tokens(already, recomendations):\n",
    "    cleaned_already = [clean_text(x) for x in already]\n",
    "    cleaned_recomendations = [clean_text(x) for x in recomendations]\n",
    "    idxs = [idx for idx, x in enumerate(cleaned_recomendations) if x not in cleaned_already]\n",
    "    return [recomendations[idx] for idx in idxs]\n",
    "\n",
    "\n",
    "def prepare_recomendations_for_print(already, recomendations):\n",
    "    text = ('Ранее вы посещали секции:\\n'\n",
    "            + '{} \\n\\n'.format(already)\n",
    "            + 'Рекомендуем вам ещё и другие секции:'\n",
    "            + '\\n{}'.format(recomendations))\n",
    "    return text\n",
    "\n",
    "def go(name):\n",
    "    \"\"\"\n",
    "    name это айди юзера для которого хотим рекомендовать\n",
    "    например 10 или 93126\n",
    "    \"\"\"\n",
    "    already, recomendations = recommend_by_userid(name, df, data, c_item, c_user, model)\n",
    "    #text_answer_for_print = prepare_recomendations_for_print(already, recomendations)\n",
    "    return already, recomendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ранее вы посещали секции:\\n[\\'Хоровое пение\\', \\'Хоровое пение\\'] \\n\\nРекомендуем вам ещё и другие секции:\\n[\\'Фортепиано \\', \\'уровень I\\', \\'Музыкальное искусство / Фортепиано / Фортепиано / \\', \\'Гусли\\', \\'Академический вокал (5 лет), уровень I\\', \\'\"Английский для всех\" микрогруппы 4-5 чел.\\', \\'4 часа в неделю\\', \\'Комплексная образовательная программа\\', \\'6 часов в неделю\\']'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаю Flask аппу на Heroku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
